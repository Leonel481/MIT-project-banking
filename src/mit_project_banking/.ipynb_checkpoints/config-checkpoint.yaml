# Parametros de entrada para el pipeline

# RandomForestClassifier:
#   n_estimators: [100, 500]
#   max_depth: [5, 20]
#   max_features: ['auto', 'sqrt', 'log2']
#   min_samples_split: [2, 10]
#   min_samples_leaf: [1, 5]
#   bootstrap: [True, False]
#   class_weight: [None, 'balanced', 'balanced_subsample']

RandomForestClassifier:
  n_estimators: [10, 10]
  max_depth: [5, 5]
  max_features: ['sqrt']
  min_samples_split: [2, 2]
  min_samples_leaf: [1, 1]
  bootstrap: [True]
  class_weight: ['balanced']

LGBMClassifier:
  objective: binary
  max_depth: [3, 10]
  learning_rate: [0.01, 0.3]
  feature_fraction: [0.5, 1.0]
  bagging_fraction: [0.5, 1.0]
  num_leaves: [20, 100]
  lambda_l1: [0.0, 1.0]
  lambda_l2: [0.0, 1.0]

XGBClassifier:
  objective: binary:logistic # Objetivo de clasificación binaria
  max_depth: [3, 10] # Profundidad máxima del árbol
  learning_rate: [0.01, 0.3] # Tasa de aprendizaje
  n_estimators: [50, 300] # Número de árboles, cantidad de boosting rounds (estimadores)
  subsample: [0.5, 1.0] # Submuestreo de filas de cada árbol, ayuda a prevenir overfitting
  colsample_bytree: [0.5, 1.0] # Submuestreo de columnas para cada árbol, ayuda a prevenir overfitting
  reg_alpha: [0.0, 1.0] # Regularización L1 (lasso)
  reg_lambda: [0.0, 1.0] # Regularización L2 (ridge), penaliza pesos grandes
  gamma: [0.0, 1.0] # Mínima reducción de pérdida para hacer una partición adicional en un nodo del árbol