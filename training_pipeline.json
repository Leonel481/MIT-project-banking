{
  "components": {
    "comp-evaluate-models": {
      "executorLabel": "exec-evaluate-models",
      "inputDefinitions": {
        "artifacts": {
          "test_data_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "all_models_and_encoder_path": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "best_model_path": {
            "parameterType": "STRING"
          },
          "metrics_path": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-load-prepare": {
      "executorLabel": "exec-load-prepare",
      "inputDefinitions": {
        "parameters": {
          "data_raw_path": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "processed_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-preprocess-and-split-data": {
      "executorLabel": "exec-preprocess-and-split-data",
      "inputDefinitions": {
        "artifacts": {
          "processed_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "test_data_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "train_data_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-models": {
      "executorLabel": "exec-train-models",
      "inputDefinitions": {
        "artifacts": {
          "train_data_csv": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "all_models_and_encoder_path": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-upload-model": {
      "executorLabel": "exec-upload-model",
      "inputDefinitions": {
        "parameters": {
          "model_display_name": {
            "parameterType": "STRING"
          },
          "model_path": {
            "parameterType": "STRING"
          },
          "model_version": {
            "parameterType": "STRING"
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-evaluate-models": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "evaluate_models"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.5.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef evaluate_models(all_models_and_encoder_path: dsl.InputPath(str), test_data_csv: dsl.InputPath(dsl.Dataset), metrics_path: dsl.OutputPath(str), best_model_path: dsl.OutputPath(str)):\n\n    # subprocess.check_call([\"pip\", \"install\", \"pandas\",\"scikit-learn\",\"xgboost\",\"lightgbm\",\"joblib\",\"google-cloud-aiplatform\"])\n\n    import pandas as pd\n    import joblib\n    import json\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n    import xgboost as xgb\n    import lightgbm as lgb\n\n    combined_artifact = joblib.load(all_models_and_encoder_path)\n    models = combined_artifact['models']\n    encoder = combined_artifact['encoder']\n\n    df_test = pd.read_csv(test_data_csv)\n    cat_features = ['payment_type','employment_status','housing_status','device_os']\n    target = 'fraud_bool'\n\n    X_test = df_test.drop(columns = [target])\n    y_test = df_test[target]\n\n    X_test_encoded = pd.DataFrame(encoder.transform(X_test[cat_features]), columns=encoder.get_feature_names_out(cat_features), index=X_test.index)\n    X_test_final = pd.concat([X_test.drop(columns=cat_features), X_test_encoded], axis=1)\n\n    all_metrics = {}\n    best_model_name = None\n    best_roc_auc_score = -1\n\n    for name, model in models.items():\n        y_pred = model.predict(X_test_final)\n\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_final)[:, 1])\n\n        all_metrics[name] = {\n            'accuracy': accuracy_score(y_test, y_pred),\n            'precision': precision_score(y_test, y_pred),\n            'recall': recall_score(y_test, y_pred),\n            'f1_score': f1_score(y_test, y_pred),\n            'roc_auc_score': roc_auc\n        }\n\n        if roc_auc > best_roc_auc_score:\n            best_roc_auc_score = roc_auc\n            best_model_name = name\n\n    with open(metrics_path, 'w') as f:\n        json.dump(all_metrics, f, indent=4)\n\n    print(f'Path metricas: {metrics_path}')\n    print(f'Resultados de los modelos entrenados: {all_metrics}')\n\n    best_model_artifact = {\n        'model': models[best_model_name],\n        'encoder': encoder\n        }\n    joblib.dump(best_model_artifact, best_model_path)\n\n    print(f'Mejor modelo {best_model_name}, path: {best_model_path}')\n\n"
          ],
          "image": "us-central1-docker.pkg.dev/projectstylus01/vertex/mit-project-custom:latest"
        }
      },
      "exec-load-prepare": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_prepare"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.5.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_prepare(data_raw_path: str, processed_csv: dsl.OutputPath(dsl.Dataset)):\n\n    # subprocess.check_call([\"pip\", \"install\", \"pandas\",\"numpy\",\"google-cloud-aiplatform\"])\n\n    import pandas as pd\n    import numpy as np\n    from datetime import datetime\n\n    df = pd.read_csv(data_raw_path) \n\n    var_nan = ['prev_address_months_count','current_address_months_count','intended_balcon_amount',\n               'bank_months_count','session_length_in_minutes','device_distinct_emails_8w']\n\n    var_cat = ['payment_type','employment_status','housing_status','source','device_os']\n\n    # Reemplazando para obtener los vacios\n    df[var_nan] = df[var_nan].replace(-1, np.nan).astype('float')\n\n    #Transformacion de variables\n    df['prev_address_valid'] = np.where(df['prev_address_months_count'] > 0,1,0)\n    df['velocity_6h'] = np.where(df['velocity_6h'] <= 0,df[\"velocity_6h\"].quantile(0.25),df[\"velocity_6h\"])\n    df['ratio_velocity_6h_24h'] = df['velocity_6h']/df['velocity_24h']\n    df['ratio_velocity_24h_4w'] = df['velocity_24h']/df['velocity_4w']\n    df['log_bank_branch_count_8w'] = np.log1p(df['bank_branch_count_8w'])\n    df['log_days_since_request'] = np.log1p(df['days_since_request'])\n    df['prev_bank_months_count'] = np.where(df['bank_months_count'] <=0, 0, 1)\n    df['income_risk_score'] = df['income']*df['credit_risk_score']\n\n    # Eliminando variables que no son consideradas relevantes para el modelo o variables que ya fueron tratadas\n    df = df.drop(columns = ['device_fraud_count','month','prev_address_months_count','intended_balcon_amount', 'source'])\n\n    df.to_csv(output_processed_csv.path, index=False)\n\n    print(f\"Datos preprocesados guardados en: {output_processed_csv.path}\")\n\n"
          ],
          "image": "us-central1-docker.pkg.dev/projectstylus01/vertex/mit-project-custom:latest"
        }
      },
      "exec-preprocess-and-split-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "preprocess_and_split_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.5.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef preprocess_and_split_data(processed_csv: dsl.InputPath(dsl.Dataset),train_data_csv: dsl.OutputPath(dsl.Dataset),test_data_csv: dsl.OutputPath(dsl.Dataset)):\n\n    # subprocess.check_call([\"pip\", \"install\", \"pandas\",\"scikit-learn\",\"google-cloud-aiplatform\"])\n\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n\n    df = pd.read_csv(processed_csv.path)\n\n    print(\"Informaci\u00f3n del DataFrame despu\u00e9s de leer el archivo procesado:\")\n    print(df.info())\n    print(\"\\nN\u00famero de filas en el DataFrame:\", len(df))\n\n    train, test = train_test_split(df, test_size=0.2, random_state=42)\n\n    train.to_csv(train_data_csv.path, index=False)\n    test.to_csv(test_data_csv.path, index=False)\n\n    print(f\"Data entrenamiento: {train_data_csv.path}\")\n    print(f\"Data test: {test_data_csv.path}\")\n\n"
          ],
          "image": "us-central1-docker.pkg.dev/projectstylus01/vertex/mit-project-custom:latest"
        }
      },
      "exec-train-models": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_models"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.5.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_models(train_data_csv: dsl.InputPath(dsl.Dataset), all_models_and_encoder_path: dsl.OutputPath(str)):\n\n    # subprocess.check_call([\"pip\", \"install\", \"pandas\",\"scikit-learn\",\"xgboost\",\"lightgbm\",\"joblib\",\"google-cloud-aiplatform\"])\n\n    import pandas as pd\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.model_selection import train_test_split\n    from sklearn.ensemble import RandomForestClassifier\n    import xgboost as xgb\n    import lightgbm as lgb\n    import joblib\n\n    df = pd.read_csv(train_data_csv.path)\n\n    cat_features = ['payment_type','employment_status','housing_status','device_os']\n    target = 'fraud_bool'\n\n    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n    encoded_features = encoder.fit_transform(df[cat_features])\n    encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(cat_features))\n\n    df_final = pd.concat([df.drop(columns=cat_features), encoded_df], axis=1)\n\n    X_train_full = df_final.drop(columns = [target])\n    y_train_full = df[target]\n\n    # Balancear\n    neg, pos = y_train_full.value_counts()[0], y_train_full.value_counts()[1]\n    scale_pos_weight = neg / pos\n\n    models = {\n        'Random Forest': RandomForestClassifier(\n            n_estimators=100,\n            class_weight='balanced',\n            random_state=42\n            ),\n        'XGBoost': xgb.XGBClassifier(\n            eval_metric='logloss',\n            scale_pos_weight=scale_pos_weight,\n            random_state=42\n            ),\n        'LightGBM': lgb.LGBMClassifier(\n            random_state=42,\n            scale_pos_weight=scale_pos_weight\n            )\n        }\n\n    trained_models = {}\n    for name, model in models.items():\n        model.fit(X_train_full, y_train_full)\n        trained_models[name] = model\n\n    models_artifacts = {\n                'models': trained_models,\n                'encoder': encoder\n                }\n\n    joblib.dump(models_artifacts, all_models_and_encoder_path)\n    print(f\"Path models y encoder: {all_models_and_encoder_path}\")\n\n"
          ],
          "image": "us-central1-docker.pkg.dev/projectstylus01/vertex/mit-project-custom:latest"
        }
      },
      "exec-upload-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "upload_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.5.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef upload_model(model_path: dsl.InputPath(str), model_display_name: str, model_version: str):\n\n    # subprocess.check_call([\"pip\", \"install\", \"pandas\",\"scikit-learn\",\"xgboost\",\"lightgbm\",\"joblib\",\"google-cloud-aiplatform\"])\n\n    from google.cloud import aiplatform\n\n    combined_artifact = joblib.load(model_path)\n    model = combined_artifact['model']\n\n    temp_model_path = 'best_model.pkl'\n    joblib.dump(model, temp_model_path)\n\n    aiplatform.init()\n\n    artifact = aiplatform.Model.upload(\n        display_name=model_display_name,\n        artifact_uri=temp_model_path,\n        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n    )\n\n    print(f\"Modelo registrado con nombre: {artifact.display_name}\")\n    print(f\"Versi\u00f3n del modelo: {model_version}\")\n\n"
          ],
          "image": "us-central1-docker.pkg.dev/projectstylus01/vertex/mit-project-custom:latest"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "Pipeline de entrenamiento modelos base que carga datos de GCS, entrena, eval\u00faa y registra un modelo.",
    "name": "end-to-end-training-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "evaluate-models": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-evaluate-models"
          },
          "dependentTasks": [
            "preprocess-and-split-data",
            "train-models"
          ],
          "inputs": {
            "artifacts": {
              "test_data_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "test_data_csv",
                  "producerTask": "preprocess-and-split-data"
                }
              }
            },
            "parameters": {
              "all_models_and_encoder_path": {
                "taskOutputParameter": {
                  "outputParameterKey": "all_models_and_encoder_path",
                  "producerTask": "train-models"
                }
              }
            }
          },
          "taskInfo": {
            "name": "evaluate-models"
          }
        },
        "load-prepare": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-load-prepare"
          },
          "inputs": {
            "parameters": {
              "data_raw_path": {
                "componentInputParameter": "input_data_uri"
              }
            }
          },
          "taskInfo": {
            "name": "load-prepare"
          }
        },
        "preprocess-and-split-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-preprocess-and-split-data"
          },
          "dependentTasks": [
            "load-prepare"
          ],
          "inputs": {
            "artifacts": {
              "processed_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "processed_csv",
                  "producerTask": "load-prepare"
                }
              }
            }
          },
          "taskInfo": {
            "name": "preprocess-and-split-data"
          }
        },
        "train-models": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-models"
          },
          "dependentTasks": [
            "preprocess-and-split-data"
          ],
          "inputs": {
            "artifacts": {
              "train_data_csv": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_data_csv",
                  "producerTask": "preprocess-and-split-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-models"
          }
        },
        "upload-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-upload-model"
          },
          "dependentTasks": [
            "evaluate-models"
          ],
          "inputs": {
            "parameters": {
              "model_display_name": {
                "componentInputParameter": "model_name"
              },
              "model_path": {
                "taskOutputParameter": {
                  "outputParameterKey": "best_model_path",
                  "producerTask": "evaluate-models"
                }
              },
              "model_version": {
                "componentInputParameter": "model_version"
              }
            }
          },
          "taskInfo": {
            "name": "upload-model"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "input_data_uri": {
          "parameterType": "STRING"
        },
        "model_name": {
          "parameterType": "STRING"
        },
        "model_version": {
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.5.0"
}